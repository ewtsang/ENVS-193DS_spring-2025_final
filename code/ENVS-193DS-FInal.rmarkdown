---
title: "ENVS 193 DS Final"
author: "Evelyn Tsang"
date: "6/11/2025"
format: 
  html: 
    toc: true
    toc_float: true
---



Link to GitHub Repository: <https://github.com/ewtsang/ENVS-193DS_spring-2025_final>

## Packages and Data:



```{r setup, message=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
#loading in libraries
library(tidyverse) #general use
library(here) #organization
library(ggeffects) #model predictions
library(janitor) #cleaning data frames
library(readxl) #reading excel sheets
library(dplyr) #data manipulation
library(ggplot2) #creating figures
library(magick) #image processing
library(DHARMa) #regression modeling
library(MuMIn) #model selection
```

```{r reading-data}
#read in SB LTER data for this assignment (problem 2)
sst <-read.csv(here("data", "SST_update2023.csv"))

#read in Swift Parrot data for this assignment (problem 3)
sp_data <-read.csv(here("data", "occdist.csv"))
```



## Problem 1. Research Writing

### a. Transparent statistical methods
In part one, the coworker used a correlation test to assess that there is no relationship between distance from headwater (km) and annual total nitrogen load (kg year-1)

In part two, the coworker used a one-way ANOVA test to see whether average nitrogen load differs across multiple source types (urban land, atmospheric deposition, fertilizer, wastewater treatment, and grasslands)

### b. More information needed
What should also be included are (1) Effect size/dist for both analyses. For example, in part 1, was correlation positive? negative? how strong was it? A p-value by itself did not indicate the strength or nature of the relationship. (2) Post-hoc comparison for part 2 is needed. Since there are multiple nitrogen sources, a significant ANOVA should be followed by pairwise comparisons (Tukey's HSD) to determine difference in sources. This would give better context for interpretation of which alnd uses are contributing the most to nitrogen.

### c. Suggestions for rewriting
*revisit this problem-------------------------------*
Sites father from the river headwaters were associated with higher total annual nitrogen loads. We rejected the null hypotheses that there is no correlation between distance from headwater (km) and annual total nitrogen load (kg year-1). Using Pearson's correlation, r = correlation coefficient, p = 0.03, a = 0.05

Nitrogen load varied significantly across different source types, indicating there is a key driver of elevated nitrogen levels to the system. We reject the null hypotheses that there is no difference in average nitrogen load between sources (urban land, atmospheric deposition, fertilizer, wastewater treatment, and grasslands) Using one way ANOVA, f=test statistic, df = degrees of freedom, p = 0.02, a = 0.05).A follow p post-hoc Tukey's HSD test determined that ___ source (mean difference = average kg/year, p = p value) had significantly higher nitrogen loads than ___source (mean difference = average kg/year, p = p-value) no significant differences were found between other sources.

## Problem 2. Data visualization
Using data from the Santa Barbara Coastal LTER on sea surface temperature in the Santa Barbara Channel area

*" Data was obtained from the NOAA National Centers for Environmental Information (NCEI) at 0.25° resolution for the time between 1982 and 2023. This Daily Optimum Interpolation Sea Surface Temperature (OISST) Analysis (Version 2.1) derived its data from satellite (Advanced Very High Resolution Radiometer (AVHRR)) and in situ platforms (i.e., ships and buoys) and yielded 18 gird points within the Santa Barbara Channel."*

### a. Cleaning and summarizing


```{r 2a-data-cleaning}
#create object called sst_clean from sst
sst_clean <- sst |> 
  mutate(date = ymd(date), #convert the "date" column to "year/month/day" format
         year = year(date), #converting to date, making sure it is in numeric values
         month = month(date, label = TRUE)) |> #extract month as abbreviated "Jan", "Feb", etc.
  filter(year %in% c("2018", "2019", "2020", "2021", "2022", "2023")) |> #only use data from 2018 to 2023
  mutate(month = factor(month, levels = month.abb, ordered = TRUE)) |>  #ensure month is an ordered factor (Jan to Dec)
#need a data frame with abbreviated month, year, and mean_monthly_sst
  group_by(year, month) |> #group by year and month for summary statistics
  summarize(mean_monthly_sst = round(mean(temp, na.rm = TRUE), 1), .groups = "drop")
#calculate average temperature per group, rounding to one decimal point
#drop grouping

sst_clean$year <- factor(sst_clean$year, levels = c("2018", "2019", "2020", "2021", "2022", "2023"))
#display 5 rows from sst_clean, in levels ("2018", "2019", "2020", "2021", "2022", and "2023"

slice_sample(sst_clean, n = 5)
#randomly display 5 rows from cleaned dataset (sst_clean) to inspect output

str(sst_clean)
#show structure of the dataset (data type, variable, etc)
```



### b. Visualize the data
*how to add20 tick to yaxis---------------------------*


```{r 2b-sst-visualization}
ggplot(data = sst_clean, #making visualization using cleaned sst data 
        aes(x = month, y = mean_monthly_sst, color = year, group = year)) + 
  #setting the axis, comparing month (x axis) and mean monthly sea surface temperature (y axis)
  scale_color_manual(
    values = colorRampPalette(c("lightblue","darkblue"))(6)
  ) + 
  #set custom blue color gradient representing 6 years
  geom_line(
    aes(group = year)) + 
  #adding lines grouped by year to show monthly trends 
  geom_point(
    aes(), 
  #adding individual data points to highlight each month's value
     size = 2) +
  #labeling the title and axis of the plot
labs(title = "Mean monthly surface temperature (C°) by year, 2018 to 2023",
       x = "Month",
       y = "Mean monthly sea surface temperature(C°)") +
  theme_minimal() + #use a clean, minimal theme
  theme(
    panel.grid = element_blank(), #remove background gridlines
    panel.border = element_rect(color = "black", fill = NA), #adding a black plot panel border
    axis.line = element_line(color = "black"), #add black axis lines
    axis.ticks = element_line(color = "black"), #adding black axis ticks
    legend.position = c(0.2, 0.7), #place legend inside plot at these coordinates
  )
```




## Problem 3. Data analysis
*Working with the nest box occupancy dataset from Stojanovic, D., Owens, G., Young, C.M., Alves, F. and Heinsohn, R. 2021. “Do nest boxes breed the target species or its competitors? A case study of a critically endangered bird.” Restoration Ecology.* DOI: [10.1111/rec.13319](https://datadryad.org/dataset/doi:10.5061/dryad.83bk3j9sb)

Answering the following research questions:
1. How do year (2016 or 2019) and distance from forest edge predict Swift Parrot (*Lathamus discolor*) nest box occupancy?
2. Is there a simpler model that explains Swift Parrot nest box occupancy, and if so, what is it?

### a. Response variable
In this dataset, a 1 or 0 marks nest box occupancy for the columns of either Swift Parrot, Common Starling, Tree Martins, or if the the nest box was empty. A 1 indicates occupancy and 0 indicates vacancy.

### b. Purpose of study
The study investigates how nest box occupancy by Swift Parrots and competing species (Tree Martins and Common Starlings) is influenced by distance from the forest edge and time since deployment. The researchers aim to evaluate whether permanent nest boxes benefit the endangered Swift Parrot or unintentionally support competitors.

### c. Difference in "seasons"
In 2016, the nest boxes were newly deployed, while in 2019 they were established and had been in place for 3 years. The years represent different breeding seasons and help assess changes in box occupancy over time.

### d. Table of models

| Model number | Edge Distance | Season          | Description                 |  
|:------------:|:-------------:|:---------------:|:----------------------------|  
| 0            |               |                 | No predictors (null model)  |
| 1            |       X       |                 | Edge distance as predictor  | 
| 2            |               |       X         | Season as predictor         |   
| 3            |       X       |       X         | All predictors (full model) |    

### e. Run the models


```{r 3e-run-models, results="hide"}
sp_data_clean <- clean_names(sp_data) #clean column names of the swift parrot data 

model10 <- lm(sp ~ 1, data = sp_data_clean) #null model: predict occupancy (sp) using only intercept (no predictors)

model11 <- lm(sp ~ edge_distance, data = sp_data_clean) #model 1: predict occupancy (sp) using forest edge distance

model12<- lm(sp ~ season, data = sp_data_clean) #model 2: predict occupancy (sp) using season (year of deployment)

model13 <- lm(sp ~ edge_distance+  season, data = sp_data_clean) #model 3: predict occupancy (sp) using both distance and season additively 
```



### f. Check the diagnostics

#### Model 0, Null model


```{r 3f-model0-diagnostics}
sim0 <- simulateResiduals(model10) #simulate residuals from model10 using DHARMa
par(mfrow = c(2,2)) #set up a 2 by 2 plot layout so that multiple diagnostic plots appear
plot(sim0) #create standard DHARMa diagnostic plots: QQ, histogram, residual v predicted, etc.
```



#### Model 1, Distance as predictor


```{r 3f-model1-diagnostics}
sim1 <- simulateResiduals(model11) #simulate residuals from model11 using DHARMa
par(mfrow = c(2,2)) #set up a 2 by 2 plot layout so that multiple diagnostic plots appear
plot(sim1) #create standard DHARMa diagnostic plots: QQ, histogram, residual v predicted, etc.

```



#### Model 2, Season as predictor


```{r 3f-model2-diagnostics}
sim2 <- simulateResiduals(model12)  #simulate residuals from model12 using DHARMa
par(mfrow = c(2,2)) #set up a 2 by 2 plot layout so that multiple diagnostic plots appear
plot(sim2) #create standard DHARMa diagnostic plots: QQ, histogram, residual v predicted, etc.
```



#### Model 3, Both season and distance as predictor


```{r 3f-model3-diagnostics}
sim3 <- simulateResiduals(model13)  #simulate residuals from model13 using DHARMa
par(mfrow = c(2,2))  #set up a 2 by 2 plot layout so that multiple diagnostic plots appear
plot(sim3) #create standard DHARMa diagnostic plots: QQ, histogram, residual v predicted, etc.
```



### g. Select the best model


```{r model-fitting}
#calculating and ordering models from best to worst to choose most supported model
AICc(model10, model11, model12, model13) |> 
  arrange(AICc) 
```



The best model to use would be **Model 3**. 

### h. Visualize the model predictions



```{r model-predictions}
#make sure "season" is treated as a categorical variable, not numeric for the plot
sp_data_clean <- sp_data_clean |> 
  mutate(season = as.factor(season))

#generate predicted values for combinations of edge_distance and season from the additive model 3
#"preds"contains predicted values, confidence intervals, grouping info
preds <- ggpredict(model13, terms = c("edge_distance [all]", "season"))

#plot with ribbons, predictions, and jittered observed data
ggplot(preds, aes(x = x, y = predicted, color = as.factor(group), fill = as.factor(group))) +
  #setting the axis: x axis = edge distance values, y axis = predicted values, color/fill by group (seasons 2016 or 2019)
  geom_line(size = 1.2) + #prediction lines
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.2, color = NA) + #adding 95% confidence interval ribbons
  geom_jitter(data = sp_data_clean, aes(x = edge_distance, y = sp, color = season), 
  #adding cleaned data, setting axis comparing edge distance (x axis) to swift parrot presence (y axis), coloring by season categories (2016 or 2019)
              inherit.aes = FALSE, width = 20, height = 0.05, alpha = 0.3) + #jitter for visibility
  #labeling title and axis of the plot
  labs(title = "Predicted Swift Parrot Nest Box Occupancy by Distance and Season",
       x = "Distance from Forest Edge (m)",
       y = "Probability of Swift Parrot Occupancy",
       color = "Season",
       fill = "Season") +
  theme_minimal() + #use a clean, minmal theme
  theme(panel.grid = element_blank(), #remove background gridlines
        panel.border = element_rect(color = "black", fill = NA), #adding a black plot panel border
        axis.line = element_line(color = "black"), #adding a black axis line
        axis.ticks = element_line(color = "black"), #adding black axis ticks
        legend.position = "right") + #setting legend position
scale_color_manual(values = c("2016" = "orange", "2019" = "yellowgreen")) + 
  scale_fill_manual(values = c("2016" = "orange", "2019" = "yellowgreen")) #sing visually distinct non-default colors for each season to improve visual clarity

```



### i. Write a caption for your figure
**Figure 1.** Predicted probability of Swift Parrot nest box occupancy based on distance from forest edge and on season (2016 vs. 2019). Lines represent model predictions from the all predictors model (occupancy ~ edge_distance + season), and shaded areas are 95% confidence intervals. Points represent raw occupancy data, jittered for visibility. **Data source:** *Stojanovic, Dejan et al. (2021). Do nest boxes breed the target species or its competitors? A case study of a critically endangered bird [Dataset]. Dryad.* [https://doi.org/10.5061/dryad.83bk3j9sb](https://doi.org/10.5061/dryad.83bk3j9sb]) 

### j. Calculate model predictions


```{r}
pred <- ggpredict(model13, terms = c("edge_distance [0, 9000]", "season")) #calculate model predictions at 0m and 9000m from forest edge for both seasons
print(pred) #display tableof predictions
```



### k. Interpret your results
Swift Parrots were less likely to use boxes farther from forest edge. Occupancy probability was higher in 2016 (new boxes) than 2019. This is likely because permanent boxes were learned and overtaken by competitors (esp. Common Starlings). Future management should prioritize temporary or seasonally-sealed boxes.
*---------To understand the biology behind the trends you found, you need to read the paper and look at the figures. For which species do you see the opposite relationship between distance to forest edge and probability of occupancy?--------------*

## Problem 4. Affective and exploratory visualizations

### a. Comparing visualizations
Compared to the exploratory visualizations made for Homework 2, visualizations made for Homework 3 were had more complexity in data represented, as well as in visual aesthetic. In Homework 2, we were prompted to create simple visualizations through *ggplot* representing categorical and continuous predictor variables. For Homework 3, we were tasked with translating our personal data into an "affective" visualization learned from lecture -- this I decided to represent in a digital painting. 

Some similarities I noticed between was using a box plot to represent the data. Although I tweaked how this was shown in my illustrative affective visualization, I kept individual data points on both of the the visualizations.

*What patterns (e.g. differences in means/counts/proportions/medians, trends through time, relationships between variables) do you see in each visualization? Are these different between visualizations? If so, why? If not, why not?----------------------------------------------------------------*

I got constructive feedback on my drafts for my affective visualization thanks to my classmates, that emotional aspect was well represented, but it was more difficult at a first glance to tell what the data was showing. To change this, I added some clearer labels to my axis and made it so that the stem length represented my data points (call length in minutes). This way, it would be clearer upon the viewer that they were looking at data.
*------------circle back on this later----------------*

### b. Sharing you affective visualization
**My final visualization of *Family Call Length vs Week of Spring Quarter* **

Final Rendition



```{r}
image<- image_read("/Users/ewtsa/Documents/ENVS-193DS/GitHub/ENVS-193DS_homework-03/HW3Draft.jpg")
grid::grid.raster(image)
```



 **Desc.** *How my emotional and academic state affects my communication with family, centering the personal, emotional rhythms of time, and relationships over a statistical background. The artwork shows the distribution of phone call duration from Week 1 to Week 10 of Spring Quarter. The median call length generally decreases from the beginning (Weeks 1-5) to the end (Weeks 6-10), which supports the initial hypothesis that call duration become shorter as academic demands increase over time.*

Homework 3 Sketch


```{r}
image<- image_read("/Users/ewtsa/Documents/ENVS-193DS/GitHub/ENVS-193DS_homework-03/HW3Paper.jpg")
grid::grid.raster(image)
```



Homework 3 Draft


```{r}
image<- image_read("/Users/ewtsa/Documents/ENVS-193DS/GitHub/ENVS-193DS_homework-03/HW3Draft.jpg")
grid::grid.raster(image)
```

